{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f99001-44f0-4e76-b429-513407662c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8b0628-18ff-432d-a596-5a66069b795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('margento_jerry_ai_dialogs_and_wildcard.gpickle', 'rb') as f:\n",
    "    jerry_ai_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ec4fff-69c9-468c-a6ce-ddd15afb7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('margento_jerry_web_searches_plus_wildcard_graph.gpickle', 'rb') as fa:\n",
    "    jerry_glasgow_web = pickle.load(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89652484-bacf-40c2-996b-87ab19aa9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('margento_jerry_mistici_hoti_nebuni_plus_wildcard_graph.gpickle', 'rb') as faro:\n",
    "    jerry_ro = pickle.load(faro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6369c14-dec0-405b-b5cc-8921ebb9ce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_jerry_graph = nx.MultiDiGraph()\n",
    "combined_jerry_graph.update(jerry_ai_graph)\n",
    "combined_jerry_graph.update(jerry_glasgow_web)\n",
    "combined_jerry_graph.update(jerry_ro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5842d6e8-eced-4b05-9c14-711da42a7de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 751\n",
      "Number of edges: 3199\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number of nodes:\", combined_jerry_graph.number_of_nodes())\n",
    "print(\"Number of edges:\", combined_jerry_graph.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8610d7-ec1e-4fab-859a-b83b1f1e521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_jerry_graph.update(jerry_ai_graph)\n",
    "combined_jerry_graph.update(jerry_glasgow_web)\n",
    "combined_jerry_graph.update(jerry_ro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ade332-de80-4fba-991a-2e9e454a9a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jerry_ai_graph - Node attribute keys: {'embedding', 'dialogue', 'text', 'speaker', 'theme'}\n",
      "jerry_glasgow_web - Node attribute keys: {'text', 'name'}\n",
      "jerry_ro - Node attribute keys: {'embedding', 'text', 'wildcard_sim'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_node_attribute_keys(graph, name=\"Graph\"):\n",
    "    all_keys = set()\n",
    "    for _, attr_dict in graph.nodes(data=True):\n",
    "        all_keys.update(attr_dict.keys())\n",
    "    print(f\"{name} - Node attribute keys:\", all_keys)\n",
    "\n",
    "print_node_attribute_keys(jerry_ai_graph, \"jerry_ai_graph\")\n",
    "print_node_attribute_keys(jerry_glasgow_web, \"jerry_glasgow_web\")\n",
    "print_node_attribute_keys(jerry_ro, \"jerry_ro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b21a12b1-0170-41de-b543-16c3f363921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794aa07c-2f25-4f29-b108-5c72a0df2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02677365-bf55-4d87-adb1-353f80853264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wildcard updated\n",
    "context = \"\"\"\n",
    "Diane Rothenberg [NOT] feeling left out of a Paradise of Poets. \n",
    "In the news: 2025. \n",
    "Crimes against humanity committed by Russia in Ukraine. \n",
    "Separatists backed by Russia also committed such crimes against Romanian-speaking Moldovans in Transnistria during the frozen conflict of 1992. \n",
    "The greatest war against children in history perpetrated by Israel in Gaza. \n",
    "President Trump and ‘vice Vance’ crave Greenland’s ice sheet while denying climate change.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49018dab-2c3c-4d8a-9824-c091de1ec6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "context_embedding = model.encode(context, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ad318c3-553d-459a-af0c-a7d663fb7eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import torch\n",
    "#import torch.nn.functional as F\n",
    "\n",
    "#def cosine_similarity(a, b):\n",
    "    #return F.cosine_similarity(a, b, dim=0).item()\n",
    "\n",
    "def add_context_similarity_edges(graph, context_embedding, similarity_threshold=0.8):\n",
    "    #context_embedding = context_embedding.cpu()  # Ensure on CPU\n",
    "\n",
    "    # Step 1: Compute similarity of each node to context\n",
    "    node_similarities = {}\n",
    "    texts = []\n",
    "    node_ids = []\n",
    "    for node_id, data in graph.nodes(data=True):\n",
    "        if \"text\" in data:\n",
    "            texts.append(data[\"text\"])\n",
    "            node_ids.append(node_id)\n",
    "\n",
    "    embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "    with open('jerry_combo_embeddings_margento_manifest_o_1.pkl', 'wb') as fp:\n",
    "            pickle.dump(embeddings, fp)\n",
    "        \n",
    "    for node_id, emb in zip(node_ids, embeddings):\n",
    "        if emb is not None:\n",
    "            # emb_tensor = torch.tensor(emb).cpu()\n",
    "            # similarity = cosine_similarity(emb_tensor, context_embedding)\n",
    "            similarity = float(util.cos_sim(emb, context_embedding).item())\n",
    "            node_similarities[node_id] = similarity\n",
    "\n",
    "    # Step 2: Get nodes similar enough to the context\n",
    "    nodes_above_thresh = [n for n, sim in node_similarities.items() if sim >= similarity_threshold]\n",
    "\n",
    "    # Step 3: For each unique pair, check similarity and add edge if not already connected\n",
    "    for i in range(len(nodes_above_thresh)):\n",
    "        for j in range(i + 1, len(nodes_above_thresh)):\n",
    "            n1, n2 = nodes_above_thresh[i], nodes_above_thresh[j]\n",
    "            sim1 = node_similarities[n1]\n",
    "            sim2 = node_similarities[n2]\n",
    "\n",
    "            source, target = (n1, n2) if sim1 > sim2 else (n2, n1)\n",
    "\n",
    "            # Avoid if an edge already exists (in either direction)\n",
    "            if graph.has_edge(source, target) or graph.has_edge(target, source):\n",
    "                continue\n",
    "\n",
    "            # Optional: Calculate a dynamic weight based on similarity difference\n",
    "            # similarity_gap = abs(sim1 - sim2)\n",
    "            #edge_weight = 2 + (1 - similarity_gap)  # You can adjust this logic\n",
    "            edge_weight = 2.7\n",
    "            \n",
    "            # Add new context-based edge\n",
    "            graph.add_edge(\n",
    "                source,\n",
    "                target,\n",
    "                weight=edge_weight,\n",
    "                relation=\"context_similar\",\n",
    "                context_similarity_source=sim1,\n",
    "                context_similarity_target=sim2\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6ab2e21-990a-4763-aee0-1d3dc46ad3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "add_context_similarity_edges(graph=combined_jerry_graph, context_embedding=context_embedding, similarity_threshold=0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "118878eb-9f7c-4719-9367-443745385ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 751\n",
      "Number of edges: 3665\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number of nodes:\", combined_jerry_graph.number_of_nodes())\n",
    "print(\"Number of edges:\", combined_jerry_graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f69ff995-a8c4-4de5-bf7f-9015bd756da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('margento_jerry_combo_graph.gpickle', 'wb') as f:\n",
    "    pickle.dump(combined_jerry_graph, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200eec12-6fde-407a-b6e4-b8219deb63cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3918project)",
   "language": "python",
   "name": "3918project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
